{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "os.makedirs('images', exist_ok=True)\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Enable GPU\n",
    "cuda = True if torch.cuda.is_available() else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring dataset and checking images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Configure data loader and image parameters\n",
    "\n",
    "img_dim = 32\n",
    "img_channels = 3\n",
    "\n",
    "os.makedirs('./data/cifar10', exist_ok=True)\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.Resize(img_dim),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset = datasets.CIFAR10(root='./data/cifar10', train=True, download=True,\n",
    "                       transform=transform)\n",
    "\n",
    "def show(img):\n",
    "    npimg = img.detach().cpu().numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i, _ = dataset[5]\n",
    "show(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "n_cpu = 1\n",
    "samples = 500\n",
    "seed = 1\n",
    "sample_interval = 5\n",
    "\n",
    "# Hyperparameters: Adam optimizer parameters (learning rate and momentum decay)\n",
    "\n",
    "lr = 0.0002\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "\n",
    "# Dimensions of latent space, GPU\n",
    "\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "ngpu = 1\n",
    "latent_dim = 100\n",
    "ngf = batch_size\n",
    "ndf = batch_size\n",
    "nc = img_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda.\n"
     ]
    }
   ],
   "source": [
    "# CPU\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# GPU\n",
    "if torch.cuda.is_available():\n",
    "        print(\"Using cuda.\")\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "\n",
    "        return output.view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to initialise weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialising and configuring metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace)\n",
      "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n",
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG = Generator().to(device)\n",
    "netG.apply(weights_init)\n",
    "print(netG)\n",
    "netD = Discriminator().to(device)\n",
    "netD.apply(weights_init)\n",
    "print(netD)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# setup optimizer\n",
    "optimizerD = torch.optim.Adam(netD.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizerG = torch.optim.Adam(netG.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "if cuda:\n",
    "    netG.cuda()\n",
    "    netD.cuda()\n",
    "    criterion.cuda()\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [64, 3, 4, 4], but got input of size [3, 32, 32] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-ed46246083d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_cpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0merrD_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0merrD_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-76-301c20484a15>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [64, 3, 4, 4], but got input of size [3, 32, 32] instead"
     ]
    }
   ],
   "source": [
    "gen_loss = []\n",
    "disc_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, data in enumerate(dataset, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # train with real\n",
    "        netD.zero_grad()\n",
    "        real_cpu = data[0].to(device)\n",
    "        batch_size = real_cpu.size(0)\n",
    "        label = torch.full((batch_size,), real_label, device=device)\n",
    "\n",
    "        output = netD(real_cpu)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # train with fake\n",
    "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        output = netD(fake.detach())\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        output = netD(fake)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "\n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "              % (epoch, epochs, i, len(dataloader),\n",
    "                 errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        \n",
    "        gen_loss.append(errG.item())\n",
    "        disc_loss.append(errD.item())\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            vutils.save_image(real_cpu,\n",
    "                    './images/real_samples.png',\n",
    "                    normalize=True)\n",
    "            fake = netG(fixed_noise)\n",
    "            vutils.save_image(fake.detach(),\n",
    "                    './images/fake_samples_epoch_%03d.png' % (epoch),\n",
    "                    normalize=True)\n",
    "            \n",
    "    plt.plot( 'Epoch', 'Loss', data=disc_loss, marker='', color='olive', linewidth=2, label='Loss_D')\n",
    "    plt.plot( 'Epoch', 'Loss', data=gen_loss, marker='', color='blue', linewidth=2, label='Loss_G')\n",
    "    plt.show()\n",
    "\n",
    "    # do checkpointing\n",
    "    torch.save(netG.state_dict(), './saved/netG_epoch_%d.pth' % (epoch))\n",
    "    torch.save(netD.state_dict(), './saved/netD_epoch_%d.pth' % (epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
