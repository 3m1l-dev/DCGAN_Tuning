{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "os.makedirs('images', exist_ok=True)\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Enable GPU\n",
    "cuda = True if torch.cuda.is_available() else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring dataset and checking images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Configure data loader and image parameters\n",
    "\n",
    "img_dim = 32\n",
    "img_channels = 3\n",
    "\n",
    "os.makedirs('./data/cifar10', exist_ok=True)\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.Resize(img_dim),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset = datasets.CIFAR10(root='./data/cifar10', train=True, download=True,\n",
    "                       transform=transform)\n",
    "\n",
    "def show(img):\n",
    "    npimg = img.detach().cpu().numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i, _ = dataset[seed]\n",
    "show(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "n_cpu = 1\n",
    "samples = 500\n",
    "seed = 1\n",
    "\n",
    "# Hyperparameters: Adam optimizer parameters (learning rate and momentum decay)\n",
    "\n",
    "lr = 0.0002\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "\n",
    "# Dimensions of latent space, GPU\n",
    "\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "ngpu = 1\n",
    "nz = 100\n",
    "ngf = img_dim\n",
    "ndf = img_dim\n",
    "nc = img_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# GPU\n",
    "if torch.cuda.is_available():\n",
    "        print(\"Using cuda.\")\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "\n",
    "        return output.view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to initialise weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialising and configuring metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(100, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace)\n",
      "    (9): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace)\n",
      "    (12): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n",
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (5): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (8): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (11): Conv2d(256, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG = Generator(ngpu).to(device)\n",
    "netG.apply(weights_init)\n",
    "print(netG)\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "netD.apply(weights_init)\n",
    "print(netD)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# setup optimizer\n",
    "optimizerD = torch.optim.Adam(netD.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizerG = torch.optim.Adam(netG.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "if cuda:\n",
    "    netG.cuda()\n",
    "    netD.cuda()\n",
    "    criterion.cuda()\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_loss = []\n",
    "disc_loss = []\n",
    "\n",
    "for epoch in range(opt.niter):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # train with real\n",
    "        netD.zero_grad()\n",
    "        real_cpu = data[0].to(device)\n",
    "        batch_size = real_cpu.size(0)\n",
    "        label = torch.full((batch_size,), real_label, device=device)\n",
    "\n",
    "        output = netD(real_cpu)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # train with fake\n",
    "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        output = netD(fake.detach())\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        output = netD(fake)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "\n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "              % (epoch, epochs, i, len(dataloader),\n",
    "                 errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        \n",
    "        gen_loss.append(errG.item())\n",
    "        disc_loss.append(errD.item())\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            vutils.save_image(real_cpu,\n",
    "                    './images/real_samples.png',\n",
    "                    normalize=True)\n",
    "            fake = netG(fixed_noise)\n",
    "            vutils.save_image(fake.detach(),\n",
    "                    './images/fake_samples_epoch_%03d.png' % (epoch),\n",
    "                    normalize=True)\n",
    "            \n",
    "    plt.plot( 'Epoch', 'Loss', data=disc_loss, marker='', color='olive', linewidth=2, label='Loss_D')\n",
    "    plt.plot( 'Epoch', 'Loss', data=gen_loss, marker='', color='blue', linewidth=2, label='Loss_G')\n",
    "    plt.show()\n",
    "\n",
    "    # do checkpointing\n",
    "    torch.save(netG.state_dict(), './saved/netG_epoch_%d.pth' % (epoch))\n",
    "    torch.save(netD.state_dict(), './saved/netD_epoch_%d.pth' % (epoch))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
